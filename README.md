# Deepfake Audio Detection

## ðŸ“Œ Overview
This project focuses on detecting **audio deepfakes** â€” synthetic voices generated by advanced AI models that threaten security, trust, and authentication systems. We compare **classical machine learning** and **deep learning** approaches for reliable detection in real-world conditions.

## ðŸš€ Methods
We employ three complementary detection strategies:

1. **MFCC + SVM**  
   - Extract Mel-Frequency Cepstral Coefficients (MFCCs).  
   - Classify with Support Vector Machine (SVM).  
   - âœ… Lightweight, computationally efficient.

2. **CQCC + GMM**  
   - Extract Constant-Q Cepstral Coefficients (CQCCs).  
   - Classify using Gaussian Mixture Models (GMMs) with log-likelihood ratios.  
   - âœ… Robust, inherits strengths from traditional anti-spoofing.

3. **CNN + Mel-Spectrograms**  
   - Convert audio into Mel-spectrograms.  
   - Train a Convolutional Neural Network (CNN) for end-to-end learning.  
   - âœ… State-of-the-art accuracy.

## ðŸ“Š Results
- **CNN**: Achieves highest accuracy on the *In-the-Wild* dataset.  
- **SVM**: Offers speed and low resource usage.  
- **CQCC-GMM**: Provides robustness against varied spoofing conditions.  

ðŸ‘‰ Together, these approaches illustrate the **trade-off between classical ML and deep learning** in audio deepfake detection.

## ðŸ”‘ Keywords
- Audio Deepfake Detection  
- Voice Spoofing  
- Support Vector Machine (SVM)  

to run the code : streamlit run detector.py

- Gaussian Mixture Model (GMM)  
- Convolutional Neural Network (CNN)  
- MFCC, CQCC, Spectrograms  






demo clip:

